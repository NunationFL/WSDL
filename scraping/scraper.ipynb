{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.zerozero.pt/edition.php?id_edicao=156405\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_chunks(l, n):\n",
    "     \n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page_source, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zerozero.pt/img/logos/edicoes/156405_imgbank_.png\n"
     ]
    }
   ],
   "source": [
    "html_scorers = soup.find(\"div\", class_=\"rbbox nofooter\")\n",
    "children = html_scorers.findChildren(\"td\" , recursive=True)\n",
    "# print(b.prettify())\n",
    "\n",
    "scorers = {}\n",
    "top_assist = {}\n",
    "assists = []\n",
    "values = []\n",
    "for x in range(1,len(children)):\n",
    "    child = children[x].find(\"div\", class_=\"text\")\n",
    "    if child != None:\n",
    "        # print(child.contents[0].text)\n",
    "        assists.append(child.contents[0].text)\n",
    "        # scorers[child.contents[0].text] = \n",
    "        # scorers[child]\n",
    "for x in range(1,len(children)):\n",
    "    child = children[x].find(\"div\", class_=\"ball_numbers\")\n",
    "    if child != None:\n",
    "        # print(child.contents[0].text)\n",
    "        values.append(child.contents[0].text)\n",
    "\n",
    "        # scorers[child.contents[0].text] = \n",
    "        # scorers[child]\n",
    "# print(scorers)\n",
    "\n",
    "for x in range(len(assists)-2):\n",
    "    scorers[assists[x]] = values[x]\n",
    "\n",
    "top_assist[assists[len(assists)-1]] = values[-1]\n",
    "\n",
    "html_league_image = soup.find(\"div\",class_=\"profile_picture\")\n",
    "league_logo = \"https://www.zerozero.pt/\" + html_league_image.find(\"img\").get(\"src\")\n",
    "print(league_logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'goals/game': '2,50', 'victories_home': '43%', 'Ties': '19%', 'victories_away': '38%', 'logo': 'https://www.zerozero.pt/img/logos/edicoes/156405_imgbank_.png'}\n"
     ]
    }
   ],
   "source": [
    "html_resume = soup.find_all(\"div\", class_=\"edition_resume_stats\")\n",
    "stats = {}\n",
    "\n",
    "stats[\"goals/game\"] = html_resume[0].text\n",
    "stats[\"victories_home\"] = html_resume[1].text\n",
    "stats[\"Ties\"] = html_resume[2].text\n",
    "stats[\"victories_away\"] = html_resume[3].text\n",
    "stats[\"logo\"] = league_logo\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = soup.find(id=\"DataTables_Table_0\").findChildren(\"tbody\")\n",
    "# print(b[1])\n",
    "\n",
    "clubs = {}\n",
    "\n",
    "for x in b[0]:\n",
    "    # print(x.prettify())\n",
    "    club_name = x.find(\"a\")\n",
    "    values = x.find_all(\"td\")\n",
    "    clubs[club_name.text] = [val.text for val in values]\n",
    "    clubs[club_name.text] += [club_name['href']]\n",
    "    time.sleep(1)\n",
    "    club_page = driver.get(\"https://www.zerozero.pt\"+club_name['href'])\n",
    "    soup2 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    team_html = soup2.find_all(id=\"team_squad\")\n",
    "\n",
    "    #get link to club image\n",
    "    html_club_image = soup2.find(\"div\",class_=\"profile_picture\")\n",
    "    club_logo = \"https://www.zerozero.pt/\" + html_club_image.find(\"img\").get(\"src\")\n",
    "\n",
    "    #get resume of the competitions it plays\n",
    "    html_competitions = soup2.find(id=\"entity_season\")\n",
    "    lines = html_competitions.find_all(\"td\")\n",
    "    y = list(divide_chunks(lines, 6))\n",
    "    competitions = {}\n",
    "    for i in range(len(y)-1):\n",
    "        competitions[y[i][0].text] = [y[i][1].text, y[i][2].text, y[i][3].text, y[i][4].text, y[i][5].text]\n",
    "\n",
    "    # #get the titles the club has\n",
    "    # html_titles = soup2.find(id=\"coach_titles\")\n",
    "    # titles = {}\n",
    "    # entries = html_titles.find_all(\"div\", class_=\"trophy\")\n",
    "    # for entry in entries:\n",
    "    #     titles[entry.find(\"div\", class_=\"text\").text] = entry.find(\"div\", class_=\"number\").text\n",
    "\n",
    "    #get the club info\n",
    "    html_club_bio = soup2.find_all(id=\"entity_bio\")\n",
    "    bio = html_club_bio[0].find_all(\"div\", class_=\"bio\")\n",
    "    bio_half = html_club_bio[0].find_all(\"div\", class_=\"bio_half\")\n",
    "    # print(bio)\n",
    "    club_info =  []\n",
    "    for y in bio:\n",
    "\n",
    "        if y.contents[1].text == \"UEFA: \":\n",
    "            club_info.append(y.contents[2].text)\n",
    "            if len(y.contents) > 4:\n",
    "                club_info.append(y.contents[5].text)\n",
    "        else:\n",
    "            club_info.append(y.contents[1].text)\n",
    "\n",
    "\n",
    "    for y in bio_half:\n",
    "        club_info.append([y.contents[1].text])\n",
    "\n",
    "    #get team players\n",
    "    team_players = {}\n",
    "    for team in team_html[0]:\n",
    "        players_per_position = team.find_all(\"div\", class_=\"staff\")\n",
    "        for player in players_per_position:\n",
    "            number = player.find(\"div\", class_=\"number\").text\n",
    "            player_name = player.find(\"div\", class_=\"name\").find(\"div\", class_=\"text\").text\n",
    "            age = player.find(\"div\", class_=\"name\").find(\"span\").text\n",
    "            link = player.find(\"div\", class_=\"name\").find(\"div\", class_=\"text\").find(\"a\")[\"href\"]\n",
    "            time.sleep(1)\n",
    "            player_page = driver.get(\"https://www.zerozero.pt/\"+link)\n",
    "            # time.sleep(random.randint(1, 5))\n",
    "\n",
    "\n",
    "            soup3 = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            html_team_games = soup3.find(id=\"team_games\")\n",
    "\n",
    "            if html_team_games != None:\n",
    "                lines = html_team_games.find_all(\"td\")\n",
    "\n",
    "                l = list(divide_chunks(lines, 5))\n",
    "                competitions_player = {}\n",
    "                for i in range(len(l)-1):\n",
    "                    competitions_player[l[i][0].text] = [l[i][1].text, l[i][2].text, l[i][3].text, l[i][4].text]\n",
    "\n",
    "            html_player_titles = soup3.find(id=\"coach_titles\")\n",
    "            player_titles = {}\n",
    "            if html_player_titles != None:\n",
    "                entries_player = html_player_titles.find_all(\"div\", class_=\"trophy\")\n",
    "                for y in entries_player:\n",
    "                    player_titles[y.find(\"div\", class_=\"competition\").text] = y.find(\"div\", class_=\"number\").text\n",
    "\n",
    "            html_history_player = soup3.find(id=\"coach_career\").find(\"table\")\n",
    "            player_clubs = {}\n",
    "            entries = html_history_player.find_all(\"td\")\n",
    "            for i in range(3):\n",
    "                player_clubs[entries[6*i+1].text] = [entries[6*i+2].text,entries[6*i+3].text, entries[6*i+4].text, entries[6*i+5].text]\n",
    "\n",
    "\n",
    "            #get link to player image\n",
    "            html_player_image = soup3.find(\"div\",class_=\"profile_picture\")\n",
    "            player_logo = html_player_image.find(\"img\").get(\"src\")\n",
    "\n",
    "\n",
    "            a = soup3.find_all(id=\"entity_bio\")\n",
    "            children = a[0].findChildren(\"div\" , recursive=False)\n",
    "            dateBirth = countryBirth =  nationality = secondNationality = naturality = position = preferedFoot = height = weight = \"\"\n",
    "            for x in range(1,len(children)):\n",
    "                child = children[x]\n",
    "                if child.find(\"span\").text ==\"Nome\":\n",
    "                    name = child.contents[1]\n",
    "                    # print(name)\n",
    "                elif child.contents[0].text ==\"Nascimento\":\n",
    "                    dateBirth = child.contents[1]\n",
    "                    # print(dateBirth)\n",
    "                    if child.find(\"div\", class_=\"text\") == \"None\":\n",
    "                        if child.findChildren(\"span\", recursive=False)[2].text == \"PaÃ­s de Nascimento\":\n",
    "                            countryBirth = child.find(\"div\", class_=\"text\").text\n",
    "                        # print(countryBirth)\n",
    "                elif child.findChildren(\"span\", recursive=False)[0].text == \"Nacionalidade\":\n",
    "                    nationality = child.contents[1].contents[1].text\n",
    "                    # print(nationality)\n",
    "                    if len(child.contents) > 3:\n",
    "                        if child.contents[2].text == \"Dupla Nacionalidade\":\n",
    "                            secondNationality = children[3].contents[3].contents[1].text\n",
    "                            # print(secondNationality)\n",
    "                elif child.find(\"span\").contents[0] == \"Naturalidade\":\n",
    "                    naturality = child.contents[1]\n",
    "                    # print(naturality)\n",
    "                elif child.find(\"span\").contents[0] == \"PosiÃ§Ã£o\":\n",
    "                    position = child.contents[1].text\n",
    "                    # print(position)\n",
    "                elif child.find(\"span\").contents[0] == \"PÃ© preferencial\":\n",
    "                    if len(child.contents) > 1:\n",
    "                        preferedFoot = child.contents[1].text\n",
    "                        # print(preferedFoot)\n",
    "                elif child.find(\"span\").contents[0] == \"Altura\":\n",
    "                    height = child.contents[1].text\n",
    "                    # print(height)\n",
    "                elif child.find(\"span\").contents[0] == \"Peso\":\n",
    "                    weight = child.contents[1].text\n",
    "                    # print(weight)\n",
    "\n",
    "            # history = soup3.find_all(\"select\", class_=\"chosen-select-search\")\n",
    "            # player_clubs = []\n",
    "            # # print(history[4])\n",
    "            # for x in history[4].find_all(\"option\"):\n",
    "            #     player_clubs.append([x.text, x.attrs[\"value\"]])\n",
    "\n",
    "\n",
    "            player[name] = [dateBirth, countryBirth, nationality, secondNationality, naturality, position, preferedFoot, height, weight, \"https://www.zerozero.pt/\"+link]\n",
    "            # player[name] += [player_clubs]\n",
    "            team_players[number] = [name, age, dateBirth, countryBirth, nationality, secondNationality, naturality, position, preferedFoot, height, weight, player_logo] + [competitions_player, player_titles, player_clubs]\n",
    "\n",
    "    clubs[club_name.text] += [team_players, competitions, club_info, club_logo, \"https://www.zerozero.pt\"+club_name['href']]\n",
    "    # print(clubs)\n",
    "    # print(name.text)\n",
    "    # print(\"HELLO\")\n",
    "    # break\n",
    "\n",
    "\n",
    "# print(clubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(clubs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'II Liga Portuguesa': '4', 'III DivisÃ£o': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clubs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup3.prettify())\n",
    "history = soup3.find_all(\"select\", class_=\"chosen-select-search\")\n",
    "for x in history[4].find_all(\"option\"):\n",
    "    print(x.text)\n",
    "    print(x.attrs[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('22_23.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(clubs))\n",
    "\n",
    "\n",
    "with open('22_23_stats.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps([stats,scorers,top_assist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player_clubs = {}\n",
    "# html_player = soup3.find_all(\"tr\")\n",
    "# # print(html_player)\n",
    "\n",
    "# # teams = a[0].findChildren(\"tbody\")\n",
    "# print(len(b))\n",
    "# for x in b:\n",
    "#     print(x)\n",
    "#     children = b[0].findChildren(\"td\" , recursive=False)\n",
    "#     season = child.contents[1]\n",
    "#     print(len(season))\n",
    "\n",
    "    \n",
    "# children = a[0].find(\"table\",class_=\"career\")\n",
    "# # table = children.find_all(\"tr\")\n",
    "# print((children))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f05704f4740528ec32f28c6a01955d2cfab9eb44c7658f067771bac1ea3accf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
